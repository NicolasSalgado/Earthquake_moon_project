{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0208951",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebf8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Packages that you may need to install\n",
    "#!pip install plotly\n",
    "#!pip install --upgrade threadpoolctl\n",
    "#!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ce203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages that we are going to use in this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import sys \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import blackman\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from functions import *\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\df\")\n",
    "from manage_file import FILES, getPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b734c87",
   "metadata": {},
   "source": [
    "# STAGE 1: INCREASING EARTHQUAKES OVER TIME\n",
    "\n",
    "## STEP 1: Read & view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# read the excel with the earthquake data.\n",
    "df_earth = pd.read_excel(getPath(FILES.input_earthquake))\n",
    "#### IMPORTANT TO RUN ####\n",
    "# Conserving only useful columns (columns that we are going to use later)\n",
    "df_earth = df_earth[[\"time\", \"year\", \"month\", \"day\", \"latitude\", \"longitude\", \"mag\", \"depth\", \"Pais\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef86a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a preview of the 10 first rows, to understand the format and the structure (you can change the number of rows to show)\n",
    "#df_earth.head(10)\n",
    "# show the columns the non null elements of each column and the type of object that python reads. \n",
    "#df_earth.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d60f7e",
   "metadata": {},
   "source": [
    "### Data formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "#Clean string of the column country, contains several spaces in the names.\n",
    "df_earth.Pais = df_earth.Pais.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d362e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "#Formatting time from string to datetime\n",
    "df_earth['time']= pd.to_datetime(df_earth['time'])\n",
    "df_earth['time'] = df_earth['time'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_earth['time']= pd.to_datetime(df_earth['time'])\n",
    "df_earth.month = df_earth.month.astype(int)\n",
    "df_earth.day= df_earth.day.astype(int)\n",
    "#df_earth.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# Sort value in case that the database is not in order on time.\n",
    "df_earth = df_earth.sort_values(by=\"time\")\n",
    "df_earth = df_earth.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7107c",
   "metadata": {},
   "source": [
    "### PLOT map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bf9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First plot on map. To visualize the data obtain\n",
    "color_scale = [(0, 'orange'), (1,'red')]\n",
    "\n",
    "fig = px.scatter_mapbox(df_earth, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        hover_name=\"index\", \n",
    "                        hover_data=[\"index\"],\n",
    "                        #color=\"cluster_label\",\n",
    "                        #color_continuous_scale=color_scale,\n",
    "                        #size=\"Listed\",\n",
    "                        zoom=1, \n",
    "                        height=800,\n",
    "                        width=800)\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb329cf",
   "metadata": {},
   "source": [
    "## STEP 2:  __Frequency for a period of time of earthquakes considering magnitude segmentation.__\n",
    "\n",
    "For ex:\n",
    "* period_length = 10 (every 10 years compare)\n",
    "* mag_seg = {magnitude < 4 |  4<= magnitude < 5 | 5 < magnitude }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# In this case we have data 1972-2023. 2023 is incomplete so we filter that year. 1972 is also incomplete.\n",
    "df_earth = df_earth[(df_earth.year < 2023) & (df_earth.year > 1972)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "######## you must want to change these piece of code ########\n",
    "\n",
    "period_length = 10 #variable to change according the period length.\n",
    "\n",
    "#############################################################\n",
    "# according to the period length select we create the labels for each row in the dataset.\n",
    "start_year = df_earth.time.iloc[0].year\n",
    "end_year = df_earth.time.iloc[-1].year\n",
    "year_range = end_year - start_year\n",
    "modulo = year_range % period_length\n",
    "if modulo == 0:\n",
    "    final_start = end_year - period_length\n",
    "else:\n",
    "    final_start = end_year - modulo\n",
    "final_end = end_year+1\n",
    "if period_length == 1:\n",
    "    starts = np.arange(start_year, final_start+1, period_length).tolist()\n",
    "    tuples = [(start, start+period_length) for start in starts]\n",
    "    # We'll add the last period calculated earlier\n",
    "    tuples.append(tuple([final_start+1, final_end]))\n",
    "else:\n",
    "    starts = np.arange(start_year, final_start, period_length).tolist()\n",
    "    tuples = [(start, start+period_length) for start in starts]\n",
    "    # We'll add the last period calculated earlier\n",
    "    tuples.append(tuple([final_start, final_end]))\n",
    "bins = pd.IntervalIndex.from_tuples(tuples, closed='left')\n",
    "\n",
    "original_labels = list(bins.astype(str))\n",
    "new_labels = ['{} - {}'.format(b.strip('[)').split(', ')[0], int(b.strip('[)').split(', ')[1])-1) for b in original_labels]\n",
    "label_dict = dict(zip(original_labels, new_labels))\n",
    "# Assign each row to a period\n",
    "df_earth['PERIOD'] = pd.cut(df_earth['year'], bins=bins, include_lowest=True, precision=0)\n",
    "df_earth['PERIOD'] = df_earth['PERIOD'].astype(\"str\")\n",
    "df_earth = df_earth.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "######## you must want to change these piece of code ########\n",
    "\n",
    "mag_seg = {0: [0,4.6], 1: [4.6,4.9], 2: [4.9,10]} #variable to change\n",
    "\n",
    "#############################################################\n",
    "# with the magnitudes segments defined we create those categories in the dataset.\n",
    "df_earth['MAG_SEG'] = [0]*len(df_earth)\n",
    "for key, value in mag_seg.items():\n",
    "    df_earth.loc[(df_earth['mag']<value[1]) & (df_earth['mag']>=value[0]), 'MAG_SEG'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have an idea of how many earthquakes are in each category of mag_seg defined.\n",
    "df_earth[\"MAG_SEG\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8dbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have de distribution of magnitudes, in the original set the min is 3.3 and max is 9.1\n",
    "df_earth = df_earth.sort_values(by=\"time\")\n",
    "df_earth[\"mag\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot to see the count of earthquakes of each mag_seg for all the periods\n",
    "fig = px.histogram(df_earth, x=\"MAG_SEG\",\n",
    "             color='PERIOD', barmode='group',\n",
    "             height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef09d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many earthquakes for each period\n",
    "df_earth.PERIOD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of number of earthquakes for each period of time.\n",
    "fig = px.histogram(df_earth, x=\"PERIOD\",\n",
    "             color='PERIOD', barmode='group',\n",
    "             height=400)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784376a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df_earth.sort_values(by=\"month\"), x=\"MAG_SEG\", color='month', barmode='group', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e18151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_earth.copy()\n",
    "df['NewDate'] = df['time'] + pd.offsets.DateOffset(days=-5)\n",
    "\n",
    "# extract the new month label from the shifted date\n",
    "df['NewMonth'] = df['NewDate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c612262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram with Plotly\n",
    "fig = px.histogram(df.sort_values(by=\"NewMonth\"), x=\"MAG_SEG\", color='NewMonth', barmode='group', height=400)\n",
    "#fig.update_layout(xaxis_title='MAG_SEG', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2411213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91155bf",
   "metadata": {},
   "source": [
    "### Country increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb338fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see number of earthquakes for each country.\n",
    "df_earth.Pais = df.Pais.fillna(\"No_Country\")\n",
    "for i,v in df_earth.Pais.value_counts().items():\n",
    "    print(f\"{i} : {v}\")\n",
    "    \n",
    "# Calculate the number of NAN in country column\n",
    "print(f'Number of NAN : {df_earth.Pais.isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb938306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the countries selected  to see the number of earthquakes for each period.\n",
    "######## you must want to change these piece of code ########\n",
    "\n",
    "_country = [\"Indonesia\", \"Japan\", \"Chile\"]\n",
    "\n",
    "##############################################################\n",
    "df_ = df_earth[df_earth.Pais.isin(_country)]\n",
    "fig = px.histogram(df_, x=\"Pais\",\n",
    "             color='PERIOD', barmode='group',\n",
    "             height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13648e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# Function to calculte the trendline.\n",
    "def trendline(data, order=1):\n",
    "    x_ = np.arange(0,len(data))\n",
    "    coeffs = np.polyfit(x_, list(data), order)\n",
    "    slope = coeffs[0]\n",
    "    return float(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d06d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the trendline for the whole series of data, and also by magnitude segment define above.\n",
    "series_totrend = df_earth.PERIOD.value_counts()\n",
    "series_totrend = series_totrend.sort_index()\n",
    "print(f\"Trendline for the whole series is : {trendline(series_totrend)}\")\n",
    "trend_results = {}\n",
    "for mag_seg in df_earth.MAG_SEG.unique().tolist():\n",
    "    df_filt = df_earth[df_earth.MAG_SEG == mag_seg]\n",
    "    series_totrend = df_filt.PERIOD.value_counts()\n",
    "    series_totrend = series_totrend.sort_index()\n",
    "    trend_results[f\"Mag Segment {mag_seg}\"] = trendline(series_totrend)\n",
    "    \n",
    "for key, value in trend_results.items():\n",
    "    print(f\"For{key} the trendline is {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bae93b",
   "metadata": {},
   "source": [
    "## Calculate period : seasonal descompose , acf, fourier and periodogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to descompose the time series of earthquakes to find seasonality\n",
    "df_ts = df_earth['year'].value_counts()\n",
    "df_ts = df_ts.sort_index()\n",
    "\n",
    "# Plot the time series data\n",
    "plt.plot(df_ts)\n",
    "\n",
    "# Calculate and plot the autocorrelation function\n",
    "plot_acf(df_ts, lags=50)\n",
    "\n",
    "# Decompose the time series into seasonal, trend, and residual components\n",
    "decomposition = seasonal_decompose(df_ts, period=12)\n",
    "fig = decomposition.plot()\n",
    "\n",
    "# Display the plots\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical algorithm to find the period of seasonality\n",
    "N = len(df_ts)\n",
    "w = blackman(N)\n",
    "y = df_ts * w\n",
    "y = fft(y.values)\n",
    "f = np.linspace(0, 1, N)\n",
    "\n",
    "# Find the dominant frequency (maximum amplitude)\n",
    "idx = np.argmax(np.abs(y))\n",
    "freq = f[idx]\n",
    "\n",
    "# Calculate the period of the seasonality\n",
    "period = 1 / freq\n",
    "\n",
    "# Plot the frequency spectrum\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(f, np.abs(y))\n",
    "ax.set_xlabel('Frequency (cycles per time unit)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b406192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periodogram seasonality\n",
    "f, Pxx = periodogram(df_ts, fs=1)\n",
    "# Plot the periodogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(f, Pxx)\n",
    "ax.set_xlabel('Frequency (cycles per time unit)')\n",
    "ax.set_ylabel('Power Spectral Density')\n",
    "plt.show()\n",
    "max_idx = np.argmax(Pxx)\n",
    "max_freq = f[max_idx]\n",
    "\n",
    "print('Maximum point: frequency = {:.4f}, PSD = {:.4f}'.format(max_freq, Pxx[max_idx]))\n",
    "period = 1 / max_freq\n",
    "print('Period of seasonality: {:.2f} time units'.format(period))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08a7ce",
   "metadata": {},
   "source": [
    "## STEP 3: Clustering based on longitude - latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "\n",
    "#drop in case of nan, but in the original case we dont find any nan\n",
    "df_earth.dropna(axis=0,how='any',subset=['latitude','longitude'],inplace=True) \n",
    "\n",
    "\n",
    "coords = df_earth[['latitude', 'longitude']]\n",
    "# Normalize the coordinates using min-max normalization\n",
    "scaler = MinMaxScaler()\n",
    "normalized_coords = scaler.fit_transform(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337013b",
   "metadata": {},
   "source": [
    "## Clustering (find best number of clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a39851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_number_of_clusters1(coords):\n",
    "    # Specify the range of k values to test\n",
    "    k_range = range(10, 70)\n",
    "\n",
    "    # Create a list to store the SSE values for each k\n",
    "    sse = []\n",
    "\n",
    "    # Loop over each value of k and compute the SSE\n",
    "    for k in k_range:\n",
    "        model = KMeans(n_clusters=k)\n",
    "        model.fit(coords)\n",
    "        sse.append(model.inertia_)\n",
    "\n",
    "    # Plot the SSE values against k\n",
    "    plt.plot(k_range, sse)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2c8d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def best_number_of_clusters2(coords):\n",
    "    K_clusters = range(10,70)\n",
    "    kmeans = [KMeans(n_clusters=i) for i in K_clusters]\n",
    "    Y_axis = coords[['latitude']]\n",
    "    X_axis = coords[['longitude']]\n",
    "    score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\n",
    "    # Visualize\n",
    "    plt.plot(K_clusters, score)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Elbow Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont recommend to run this cell, take a long time to compute. I have comment those functions.\n",
    "\n",
    "#best_number_of_clusters1(coords)\n",
    "#best_number_of_clusters2(coords)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7b165",
   "metadata": {},
   "source": [
    "## Clustering and plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# Calculte and create the clustering. HERE I USE COORDS\n",
    "kmeans = KMeans(n_clusters =60 , init ='k-means++')\n",
    "\n",
    "kmeans.fit(coords) # Compute k-means clustering.\n",
    "df_earth['cluster_label'] = kmeans.fit_predict(coords)\n",
    "labels = kmeans.predict(coords) # Labels of each point\n",
    "centers = kmeans.cluster_centers_ # Coordinates of cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the dataset with cluster label on map.\n",
    "\n",
    "color_scale = [(0, 'yellow'), (1,'blue')]\n",
    "\n",
    "fig = px.scatter_mapbox(df_earth, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        hover_name=\"index\", \n",
    "                        hover_data=[\"index\"],\n",
    "                        color=\"cluster_label\",\n",
    "                        color_continuous_scale=color_scale,\n",
    "                        #size=\"Listed\",\n",
    "                        zoom=1, \n",
    "                        height=800,\n",
    "                        width=800)\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7beef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANT TO RUN ####\n",
    "# Calculte and create the clustering. HERE I USE NORMALIZED COORDS (corods change to a normal distribution)\n",
    "#kmeans = KMeans(n_clusters =60 , init ='k-means++')\n",
    "\n",
    "#kmeans.fit(normalized_coords) # Compute k-means clustering.\n",
    "#df_earth['cluster_label'] = kmeans.fit_predict(normalized_coords)\n",
    "#labels_norm = kmeans.predict(normalized_coords) # Labels of each point\n",
    "#centers_norm = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "\n",
    "color_scale = [(0, 'orange'), (1,'red')]\n",
    "df_filt = df_earth[df_earth.cluster_label.isin([0, 13, 58, 8])]\n",
    "fig = px.scatter_mapbox(df_filt, \n",
    "                        lat=\"latitude\", \n",
    "                        lon=\"longitude\", \n",
    "                        hover_name=\"index\", \n",
    "                        hover_data=[\"index\"],\n",
    "                        color=\"cluster_label\",\n",
    "                        #color_continuous_scale=color_scale,\n",
    "                        #size=\"Listed\",\n",
    "                        zoom=1, \n",
    "                        height=800,\n",
    "                        width=800)\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51dc39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot of the same data but in a normal graph. Not pretty useful.\n",
    "df_earth.plot.scatter(x = 'longitude', y = 'latitude', c=labels, s=2, cmap='plasma')\n",
    "plt.scatter(centers[:, 1], centers[:, 0], c='black', s=4, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd141e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate trendline by cluster , FOR ALL CLUSTERS\n",
    "trend_results_cluster = {}\n",
    "for c in df_earth[\"cluster_label\"].unique().tolist():\n",
    "    df_filt = df_earth[df_earth.cluster_label == c]\n",
    "    series_totrend = df_filt.PERIOD.value_counts()\n",
    "    series_totrend = series_totrend.sort_index()\n",
    "    trend_results_cluster[f\"Cluster {c}\"] = round(trendline(series_totrend),2)\n",
    "for key, value in trend_results_cluster.items():\n",
    "    print(f\"For {key} the trendline is {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_results_cluster =dict(sorted(trend_results_cluster.items(), key=lambda item: item[1], reverse=True))\n",
    "trend_results_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc95a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the cluster of your interest\n",
    "cluster = 8\n",
    "df_filt = df_earth[df_earth.cluster_label == cluster]\n",
    "print(f\"Cantidad de data del cluster {cluster} es {len(df_filt)}\")\n",
    "series_totrend = df_filt.PERIOD.value_counts()\n",
    "series_totrend = series_totrend.sort_index()\n",
    "print(series_totrend)\n",
    "print(f\"Cluster {cluster} has a trend of {trendline(series_totrend)}\")\n",
    "#for key, value in trend_results_cluster.items():\n",
    "#    print(f\"For {key} the trendline is {value}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec037a1",
   "metadata": {},
   "source": [
    "# STAGE 2:  Relation between moon and eartquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first read moon data\n",
    "df_moon = pd.read_excel(getPath(FILES.input_moon))\n",
    "\n",
    "#Use depth to filter. if the deppth one are connected to the moon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed45bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change columns name and reorder\n",
    "df_moon.columns = [\"year\", \"day\", \"month\", \"acum_day\", \"ill_frac\", \"r/km\", \"dec\", \"ra/h\", \"ra/Â°\"]\n",
    "# 384400km\n",
    "# ill frac new and full moon\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78863bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill column year.\n",
    "df_moon.year = df_moon.year.replace({\"common year\": np.NaN, \"leap year\": np.NaN})\n",
    "df_moon.year.ffill(inplace=True)\n",
    "df_moon.year = df_moon.year.astype(int)\n",
    "df_moon.dropna(inplace=True)\n",
    "df_moon.month = df_moon.month.astype(int)\n",
    "df_moon.day= df_moon.day.astype(int)\n",
    "df_moon.acum_day= df_moon.acum_day.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moon[\"r/km\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4143d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moon.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moon = df_moon.sort_index()\n",
    "df_moon.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_earth.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ef880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged data earthquake with data moon\n",
    "# df earthquake : year, month, day\n",
    "# df moon       : Year, Month, date\n",
    "df_merged = pd.merge(df_earth, df_moon, left_on=['year', 'month', 'day'], right_on=['year', 'month', 'day'], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64298c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to perfom interpolation of a certain variable.\n",
    "def interpolate_position(original_position, final_position, datetime):\n",
    "    \"\"\"\n",
    "    Perform a linear interpolation of the position of the moon at a specific datetime.\n",
    "\n",
    "    Parameters:\n",
    "    original_position (float): The position of the moon at the beginning of the day.\n",
    "    final_position (float): The position of the moon at the end of the day.\n",
    "    datetime: The datetime in the format 'yyyy-mm-dd hh:mm:ss'.\n",
    "    Returns:\n",
    "    float: The interpolated position of the moon at the specified datetime.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract year, day, and month information from the datetime object\n",
    "    year, day, month = datetime.year, datetime.day, datetime.month\n",
    "\n",
    "\n",
    "    # Compute the fraction of the day passed by\n",
    "    time_passed = (datetime - datetime.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "    total_time = (pd.to_datetime(datetime.date()) + pd.DateOffset(days=1) - pd.to_datetime(datetime.date())).total_seconds()\n",
    "\n",
    "    # Interpolate the position of the moon linearly based on the fraction of the day passed by\n",
    "    interpolated_position = original_position + (final_position - original_position) * time_passed / total_time\n",
    "    #print(\"datetime: \", datetime)\n",
    "    #print(f\"Original Position {original_position} - Final Position {final_position} - interpolated_position: {interpolated_position}\")\n",
    "    return interpolated_position\n",
    "\n",
    "def apply_interpolation(df_merged, df_moon, var_name=[\"r/km\"]):\n",
    "    count = 0\n",
    "    df_merged[f\"{var_name}_interpolated\"] = [0]*len(df_merged)\n",
    "    for index, row in df_merged.iterrows():\n",
    "        next_day = pd.to_datetime(row[\"time\"] + pd.DateOffset(days=1))\n",
    "        try:\n",
    "            next_row = df_moon[(df_moon.year == next_day.year) & (df_moon.month == next_day.month) & (df_moon.day == next_day.day)].iloc[0]\n",
    "        except:\n",
    "            next_row = None\n",
    "        if (not np.isnan(row[var_name])) and (not next_row is None) :\n",
    "            for var_name in vars_names:\n",
    "                datetime = row[\"time\"]\n",
    "                original_pos = row[var_name]\n",
    "                final_pos    = next_row[var_name]\n",
    "                df_merged.loc[index,f\"{var_name}_interpolated\"] = interpolate_position(original_pos, final_pos, datetime)\n",
    "            \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = \"r/km\" # variable to interpolate\n",
    "df_merged = apply_interpolation(df_merged, df_moon, var_name) #This line apply the interpolation. This line will take time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3e1fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged\n",
    "#10-0-10 new\n",
    "#90-100-90  full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged[\"r/km_interpolated\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"minalbe_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed7036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
